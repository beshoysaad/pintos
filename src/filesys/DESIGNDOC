		     +-------------------------+
		     |            OS           |
		     | PROJECT 4: FILE SYSTEMS |
		     |     DESIGN DOCUMENT     |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Beshoy Saad         <s8besaad@stud.uni-saarland.de> 2572741
Sandro Montemezzani <s8samont@stud.uni-saarland.de> 2563261

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

Inode pointer structure: https://en.wikipedia.org/wiki/Inode_pointer_structure

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct bcache_entry
{
  struct list_elem elem;        // entry for the buffer cache list
  struct block_device *device;  // the block device this entry currently holds data for
  block_sector_t sector;        // the sector on that block device
  uint8_t *buffer;              // pointer to the buffer where the contents are stored
  bool dirty;                   // wether the contents differ from what is currently on the disk
  bool used;                    // the used bit for the CLOCK eviction algorithm
  struct lock lock;             // general lock for accessing/modifying the metadata of this entry
  struct lock cntlock;          // lock for accessing/modifying the data contents of this entry
};
This struct holds all metadata needed for a single
entry in the buffer cache.

struct bcache_data
{
  struct block_device  *device;  the block device to read the block from
  block_sector_t       sector;   the sector from that should be read
};
This is used as data packet that is being sent to the
read-ahead thread.

`static struct list bcache_entry_list;'
List holding all Buffer Cache Entries

`static struct lock usage_flow_lock;
 static struct condition usage_flow_condition;
 static unsigned usage_flow_count;'
When a thread starts iterating over the entries, `usage_flow_count' is increased.
When it leaves the loop, `usage_flow_count' is decreased again. Other threads can
wait for a usage flow to exit using `sage_flow_condition'.

`static struct lock modification_flow_lock;
 static struct condition modification_flow_condition;
 static unsigned modification_flow_count;'
When a thread wants to modify the entries list (i.e add or remove entries), it
will increase `modification_flow_count'. When a thread is waiting to enter a
modification flow, other threads will no longer enter usage flows. Once all
usage flows have exited, the list can be modified and waiting threads can be
notified using `modification_flow_condition'.

`static bool bcache_stop_write_behind;'
Boolean flag to indicate the periodical write-behind thread that it
stop.

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

Our code implements the CLOCK eviction algorithm. It keeps a pointer
into the list of entries. To find a entry that can be evicted, the
entry pointed by the pointer is taken. If it has the used-bit set,
that will be unset, the pointer will move forward one item and then
the process is started over again. If the used-bit is not set, this
entry is chosen for eviction.

>> C3: Describe your implementation of write-behind.

If the contents of a cache entry is modified, it will just be marked as "dirty"
and not written back to disk immediatly. Then contents will then only be
written back to disk once that cache entry is evicted. Every 1000 ticks, a
seperate thread loops over all entries and writes back all dirty once.
The number 1000 empirically chosen at this point, at corresponds to roughly
8 seconds to the development machines being used.

>> C4: Describe your implementation of read-ahead.

Read-ahead is used when blocks are read from a file. If N blocks are requested
from a file, then the N+1th block will be loaded into cache asynchronously after
the call for the N blocks returns.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

Each cache entry has two locks for the metadata and for the data content.
To evict a entry, both locks need to be aquired.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

Similarly, to access a cache entry, the metadata lock needs to be acquired
first, potentially followed by the data lock. Since the evicting process will
hold these locks during eviction, no other processes are accessing the data at
the same time.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Files that are opened multiple times in short time periods clearly benefit from
it, as the disk operation, which is taking long time compared to other calculations
by the program, only needs to be performed once.
Read-ahead is beneficial for example for a file decoder, where the file blocks
are read continuous and in order, but only in small chunks at a time.
Similarly the file encoder would benefit from Write-behind, since the data is not
dumped to disk after every chunk that is written to the file.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
